{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75e321ca-8478-4309-b0a9-3f64e432df99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# sigmoid 함수\n",
    "def sigmoid(x):\n",
    "    return 1 / (1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5def5fdb-6806-4241-9b6c-009cf92b6055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수치미분 함수\n",
    "def numerical_derivative(f, x):\n",
    "    delta_x = 1e-4 # 0.0001\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index        \n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x) # f(x+delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val - delta_x \n",
    "        fx2 = f(x) # f(x-delta_x)\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val \n",
    "        it.iternext()   \n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "57647d2a-0b4b-4faf-beb9-0c84854df0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LogicGate2:\n",
    "    \n",
    "    def __init__(self, gate_name, xdata, tdata):\n",
    "        \n",
    "        self.name = gate_name\n",
    "        \n",
    "        # 입력 데이터, 정답 데이터 초기화\n",
    "        self.__xdata = xdata.reshape(4, 2)\n",
    "        self.__tdata = tdata.reshape(4, 1)\n",
    "        \n",
    "        # 2층 hidden layer unit : 6개 가정, 가중치 W2, 바이어스 b2 초기화\n",
    "        self.__W2 = np.random.rand(2,6) # weight, 2 x 6 matrix\n",
    "        self.__b2 = np.random.rand(6)\n",
    "        \n",
    "        # 3층 output layer unit : 1개, 가중치 W3, 바이어스 b3 초기화\n",
    "        self.__W3 = np.random.rand(6,1)\n",
    "        self.__b3 = np.random.rand(1)\n",
    "        \n",
    "        self.__learning_rate = 1e-2\n",
    "        \n",
    "        print(self.name + \" object is created\")\n",
    "        \n",
    "    def feed_forward(self):\n",
    "        \n",
    "        delta = 1e-7\n",
    "        \n",
    "        z2 = np.dot(self.__xdata, self.__W2) + self.__b2 # 은닉층의 선형회귀 값\n",
    "        a2 = sigmoid(z2) # 은닉층의 출력\n",
    "        \n",
    "        z3 = np.dot(a2, self.__W3) + self.__b3 # 출력층의 선형회귀 값\n",
    "        y = a3 = sigmoid(z3) # 출력층의 출력\n",
    "        \n",
    "        return -np.sum(self.__tdata * np.log(y + delta) + (1 - self.__tdata) * np.log((1 - y) + delta))\n",
    "        \n",
    "        \n",
    "    def loss_val(self): # 외부 출력을 위한 손실함수(cross-entropy) 값 계산\n",
    "        \n",
    "        delta = 1e-7\n",
    "        \n",
    "        z2 = np.dot(self.__xdata, self.__W2) + self.__b2\n",
    "        a2 = sigmoid(z2)\n",
    "        \n",
    "        z3 = np.dot(a2, self.__W3) + self.__b3\n",
    "        y = a3 = sigmoid(z3)\n",
    "        \n",
    "        return -np.sum(self.__tdata * np.log(y + delta) + (1 - self.__tdata) * np.log((1 - y) + delta))\n",
    " \n",
    "    def train(self):\n",
    "        \n",
    "        f = lambda x : self.feed_forward()\n",
    "        \n",
    "        print('Initial loss value = ', self.loss_val())\n",
    "        \n",
    "        for step in range(10001):\n",
    "            \n",
    "            self.__W2 -= self.__learning_rate * numerical_derivative(f, self.__W2)\n",
    "            self.__b2 -= self.__learning_rate * numerical_derivative(f, self.__b2)\n",
    "            self.__W3 -= self.__learning_rate * numerical_derivative(f, self.__W3)\n",
    "            self.__b3 -= self.__learning_rate * numerical_derivative(f, self.__b3)\n",
    "            \n",
    "            if (step % 400 == 0):\n",
    "                print(\"step = \", step, \"loss value = \", self.loss_val())\n",
    "                \n",
    "    def predict(self, xdata):\n",
    "        \n",
    "        z2 = np.dot(xdata, self.__W2) + self.__b2 # 은닉층의 선형회귀 값\n",
    "        a2 = sigmoid(z2) # 은닉층의 출력\n",
    "        \n",
    "        z3 = np.dot(a2, self.__W3) + self.__b3 # 출력층의 선형회귀 값\n",
    "        y = a3 = sigmoid(z3) # 출력층의 출력\n",
    "        \n",
    "        if y > 0.5:\n",
    "            result = 1\n",
    "        else:\n",
    "            result = 0\n",
    "            \n",
    "        return y, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d36bab49-070d-4fe5-a46f-ff9c41120934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AND_GATE object is created\n",
      "Initial loss value =  8.86598842701466\n",
      "step =  0 loss value =  8.553596526833829\n",
      "step =  400 loss value =  2.168773863241032\n",
      "step =  800 loss value =  1.965907120403696\n",
      "step =  1200 loss value =  1.659529674471039\n",
      "step =  1600 loss value =  1.307835778085088\n",
      "step =  2000 loss value =  0.9909748689680493\n",
      "step =  2400 loss value =  0.7371213828610498\n",
      "step =  2800 loss value =  0.550005031350226\n",
      "step =  3200 loss value =  0.4182345840932329\n",
      "step =  3600 loss value =  0.32631094646303527\n",
      "step =  4000 loss value =  0.26136845281046084\n",
      "step =  4400 loss value =  0.2144446085035564\n",
      "step =  4800 loss value =  0.17967388190893124\n",
      "step =  5200 loss value =  0.1532668805811156\n",
      "step =  5600 loss value =  0.1327527559211782\n",
      "step =  6000 loss value =  0.11649005226299271\n",
      "step =  6400 loss value =  0.1033640220972527\n",
      "step =  6800 loss value =  0.09260038613009244\n",
      "step =  7200 loss value =  0.08364956799091963\n",
      "step =  7600 loss value =  0.07611349610737482\n",
      "step =  8000 loss value =  0.06969839750121687\n",
      "step =  8400 loss value =  0.06418372798511711\n",
      "step =  8800 loss value =  0.05940131109803671\n",
      "step =  9200 loss value =  0.05522106237158872\n",
      "step =  9600 loss value =  0.051541043557486545\n",
      "step =  10000 loss value =  0.04828041660898091\n"
     ]
    }
   ],
   "source": [
    "xdata = np.array([ [0,0], [0,1], [1,0], [1,1] ])\n",
    "tdata = np.array([0,0,0,1])\n",
    "\n",
    "AND_obj = LogicGate2(\"AND_GATE\", xdata, tdata)\n",
    "\n",
    "AND_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "325a4153-2f23-458c-a254-f1b7721f7471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AND_GATE \n",
      "\n",
      "[0 0]  =  0 \n",
      "\n",
      "[0 1]  =  0 \n",
      "\n",
      "[1 0]  =  0 \n",
      "\n",
      "[1 1]  =  1 \n",
      "\n",
      "(array([0.00030379]), 0)\n",
      "(array([0.01199231]), 0)\n",
      "(array([0.01267523]), 0)\n",
      "(array([0.97711009]), 1)\n"
     ]
    }
   ],
   "source": [
    "print(AND_obj.name, \"\\n\")\n",
    "\n",
    "test_data = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "\n",
    "for input_data in test_data:\n",
    "    (sigmoid_val, logical_val) = AND_obj.predict(input_data)\n",
    "    print(input_data, \" = \", logical_val, \"\\n\")\n",
    "\n",
    "for data in test_data:\n",
    "    print(AND_obj.predict(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5762d9f7-5eac-4c3a-9918-3051f4e48caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XOR_GATE object is created\n",
      "Initial loss value =  4.97469148381823\n",
      "step =  0 loss value =  4.8799007346101835\n",
      "step =  400 loss value =  2.7665805268478936\n",
      "step =  800 loss value =  2.7638131615589336\n",
      "step =  1200 loss value =  2.759726905707175\n",
      "step =  1600 loss value =  2.7535046435133625\n",
      "step =  2000 loss value =  2.7438963317932723\n",
      "step =  2400 loss value =  2.729135479968894\n",
      "step =  2800 loss value =  2.7069719901382556\n",
      "step =  3200 loss value =  2.674787302724853\n",
      "step =  3600 loss value =  2.6296910137314455\n",
      "step =  4000 loss value =  2.5688722265199533\n",
      "step =  4400 loss value =  2.490854579511729\n",
      "step =  4800 loss value =  2.3972234681206235\n",
      "step =  5200 loss value =  2.2925878884373554\n",
      "step =  5600 loss value =  2.181987844447944\n",
      "step =  6000 loss value =  2.068311046410521\n",
      "step =  6400 loss value =  1.9516469371356686\n",
      "step =  6800 loss value =  1.830084332639232\n",
      "step =  7200 loss value =  1.701158124176943\n",
      "step =  7600 loss value =  1.563604683464585\n",
      "step =  8000 loss value =  1.4187968376628064\n",
      "step =  8400 loss value =  1.2709111493618215\n",
      "step =  8800 loss value =  1.1256019853486903\n",
      "step =  9200 loss value =  0.9881628024602578\n",
      "step =  9600 loss value =  0.8623488892377117\n",
      "step =  10000 loss value =  0.7501486359450804\n"
     ]
    }
   ],
   "source": [
    "xdata = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "tdata = np.array([0,1,1,0])\n",
    "\n",
    "XOR_obj = LogicGate2(\"XOR_GATE\", xdata, tdata)\n",
    "\n",
    "XOR_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a617e064-6e6a-400d-ad3e-11b1c59724c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XOR_GATE \n",
      "\n",
      "[0 0]  =  0 \n",
      "\n",
      "[0 1]  =  1 \n",
      "\n",
      "[1 0]  =  1 \n",
      "\n",
      "[1 1]  =  0 \n",
      "\n",
      "(array([0.10985678]), 0)\n",
      "(array([0.84608213]), 1)\n",
      "(array([0.81652328]), 1)\n",
      "(array([0.23197848]), 0)\n"
     ]
    }
   ],
   "source": [
    "print(XOR_obj.name, \"\\n\")\n",
    "\n",
    "test_data = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "\n",
    "for input_data in test_data:\n",
    "    (sigmoid_val, logical_val) = XOR_obj.predict(input_data)\n",
    "    print(input_data, \" = \", logical_val, \"\\n\")\n",
    "    \n",
    "for data in test_data:\n",
    "    print(XOR_obj.predict(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a09bc0-c297-4178-8305-fb5cfe80fe6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
